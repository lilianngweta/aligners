{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from genai.model import Credentials, Model\n",
    "from genai.schemas import GenerateParams\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load Credentials\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_endpoint = os.getenv(\"GENAI_API\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_new_tokens must be <= 1536\n",
    "params = GenerateParams(decoding_method=\"greedy\", min_new_tokens=1, max_new_tokens=1500, stop_sequences=[\"\\n\\n\\nInput:\"], repetition_penalty=2)\n",
    "\n",
    "# creds object\n",
    "creds = Credentials(api_key, api_endpoint)\n",
    "\n",
    "# model object\n",
    "model = Model(\"tiiuae/falcon-40b\", params=params, credentials=creds)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./questions/tgrt_questions.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prompt formatter function for when initial output is not included \n",
    "def prompt_formatter(instr, input_text):\n",
    "    prompt = instr + '\\n\\n' + 'Input:\\n' + input_text + '\\n' + 'Response:'\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Read aligner principles + in-context examples\n",
    "corrector_principles = open(\"./prompts/factuality_aligner_principles_and_examples.txt\", \"r\").read()\n",
    "print(corrector_principles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "j = 0 # keeps track of folder numbers\n",
    "start_index = 0 \n",
    "end_index = 152997 # last question index number\n",
    "index_tracker = None\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for index in range(start_index, end_index, batch_size):\n",
    "    data_batch = data[index:index+batch_size]\n",
    "\n",
    "    ''' x[0] contains 'question' '''\n",
    "    prompts_no_output = [prompt_formatter(corrector_principles, str(x[0]).strip()) for x in data_batch.to_numpy()]\n",
    "    \n",
    "\n",
    "    questions = []\n",
    "    responses = []\n",
    "    problems = []\n",
    "    corrected_responses = []\n",
    "    bad_response_indeces = []\n",
    "    none_response_indeces = []\n",
    "    i = 0\n",
    "    for response in model.generate_async(prompts_no_output):\n",
    "        \n",
    "        index_tracker = index + i\n",
    "        if response is not None:\n",
    "            result = response.generated_text.strip()\n",
    "\n",
    "            # initializing substrings (used to obtain indeces for string slicing)\n",
    "            sub_response = \"\\nCorrector\"\n",
    "\n",
    "            sub1_problems = \"response):\"\n",
    "            sub2_problems = \"\\nCorrector:\\n\"\n",
    "\n",
    "            sub_corrector = \"\\nCorrector:\"\n",
    "            \n",
    "            sub1_question = \"\\nInput:\"\n",
    "            sub2_question = \"\\nResponse:\"\n",
    "\n",
    "\n",
    "            if sub_response in result and sub1_problems in result and sub2_problems in result and sub_corrector in result:\n",
    "\n",
    "                question = response.input_text\n",
    "\n",
    "                # getting indeces of substrings\n",
    "                idx_response = result.index(sub_response)\n",
    "\n",
    "                idx1_problems = result.index(sub1_problems)\n",
    "                idx2_problems = result.index(sub2_problems)\n",
    "\n",
    "                idx_corrector = result.index(sub_corrector)\n",
    "                \n",
    "                idx1_question = question.rindex(sub1_question)\n",
    "                idx2_question = question.rindex(sub2_question)\n",
    "\n",
    "                # length of substring 1 is added to get string from next character\n",
    "                res_response = result[0: idx_response].strip()\n",
    "                res_problems = result[idx1_problems + len(sub1_problems) + 1:idx2_problems].strip()\n",
    "                res_corrector = result[idx_corrector + len(sub_corrector) + 1:].strip()\n",
    "                res_question = question[idx1_question + len(sub1_question) + 1:idx2_question].strip()\n",
    "\n",
    "                # adding extracted strings to their respective lists\n",
    "                responses.append(res_response)\n",
    "                problems.append(res_problems)\n",
    "                corrected_responses.append(res_corrector)\n",
    "                questions.append(res_question)\n",
    "                print(\"=====================================================================\")\n",
    "                print(\"End of response for index: \", index_tracker)\n",
    "                print(\"=====================================================================\")\n",
    "            else:\n",
    "                bad_response_indeces.append(index_tracker)\n",
    "                print(\"*******************************************************\")\n",
    "                print(\"Bad response at index: \", index_tracker)\n",
    "                print(\"*******************************************************\")\n",
    "                \n",
    "        else:\n",
    "            none_response_indeces.append(index_tracker)\n",
    "            print(\"*******************************************************\")\n",
    "            print(\"None response at index: \", index_tracker)\n",
    "            print(\"*******************************************************\")\n",
    "\n",
    "        i = i+1\n",
    "        \n",
    "    batch_df = pd.DataFrame(questions, columns=['input'])\n",
    "    batch_df[\"initial_response\"] = responses\n",
    "    batch_df[\"response_problems\"] = problems\n",
    "    batch_df[\"corrected_reponse\"] = corrected_responses\n",
    "    batch_df.to_csv('./data/generated_data'+str(j)+'_'+str(index_tracker)+'.csv', index=False)\n",
    "    \n",
    "    if len(bad_response_indeces)>0:\n",
    "        bad_df = pd.DataFrame(bad_response_indeces, columns=['bad_response_index'])\n",
    "        bad_df.to_csv('./data/bad_responses/bad'+str(j)+'.csv', index=False)\n",
    "    if len(none_response_indeces)>0:\n",
    "        none_df = pd.DataFrame(none_response_indeces, columns=['none_response_index'])\n",
    "        none_df.to_csv('./data/bad_responses/none'+str(j)+'.csv', index=False)\n",
    "    end_time = time.time()\n",
    "    print(\"#################################################################################################\")\n",
    "    print(\"Generated data batch saved at index: \", index_tracker, \" Time taken: \", end_time-start_time)\n",
    "    print(\"#################################################################################################\")\n",
    "    j = j+1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
